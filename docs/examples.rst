##########################
Examples, Demos, Tutorials 
##########################

This page introduces various demos, examples, and tutorials currently available with the Ryzenâ„¢ AI Software. 

************************
Getting Started Tutorial
************************

- The :doc:`Getting Started Tutorial <getstartex>` deploys a custom ResNet model demonstrating: 

  - Pretrained model conversion to ONNX 
  - Quantization using Vitis AI ONNX quantizer 
  - Deployment using ONNX Runtime C++ and Python code


********
Examples
********

- `Run Vitis AI ONNX Quantizer example <example/onnx_quantizer>`_
- `Real-time object detection with Yolov8 <example/yolov8>`_
- `Run multiple concurrent AI applications with ONNXRuntime <example/multi-model>`_
- `Run Ryzen AI Library example <example/Ryzen-AI-Library>`_
- `Run ONNX end-to-end examples with custom pre/post-processing nodes running on IPU <https://github.com/amd/RyzenAI-SW/tree/main/example/onnx-e2e>`_
- Generative AI Examples
   - `Run LLM OPT-1.3B model with ONNXRuntime <example/transformers/>`_
   - `Run LLM OPT-1.3B model with PyTorch <example/transformers/>`_
   - `Run LLM Llama 2 model with PyTorch <example/transformers/>`_

*****
Demos
*****

- `Cloud-to-Client demo on Ryzen AI <demo/cloud-to-client>`_
- `Multiple model concurrency demo on Ryzen AI <demo/multi-model-exec>`_


*********
Tutorials
*********

- `A Getting Started Tutorial with a fine-tuned ResNet model <tutorial/getting_started_resnet>`_
- `Hello World Jupyter Notebook Tutorial <tutorial/hello_world>`_
- `End-to-end Object Detection <tutorial/yolov8_e2e>`_
- `Quantization for Ryzen AI <tutorial/RyzenAI_quant_tutorial>`_

************
Benchmarking 
************

- `ONNX Benchmarking utilities <onnx-benchmark>`_




- `Run multiple concurrent AI applications with ONNXRuntime <https://github.com/amd/RyzenAI-SW/tree/main/example/multi-model>`_  
- `Real-time object detection with Yolov8 <https://github.com/amd/RyzenAI-SW/tree/main/example/yolov8>`_
- `Run LLM OPT-1.3B model with ONNXRuntime <https://github.com/amd/RyzenAI-SW/tree/main/example/transformers/opt-onnx>`_  
- `Run LLM OPT-1.3B model with PyTorch <https://github.com/amd/RyzenAI-SW/tree/main/example/transformers>`_  
- `Run LLM Llama 2 model with PyTorch <https://github.com/amd/RyzenAI-SW/tree/main/example/transformers>`_
- `Run ONNX end-to-end examples with custom pre/post-processing nodes running on NPU <https://github.com/amd/RyzenAI-SW/tree/main/example/onnx-e2e>`_  



- `Cloud-to-Client demo on Ryzen AI <https://github.com/amd/RyzenAI-SW/tree/main/demo/cloud-to-client>`_ 
- `Multiple model concurrency demo on Ryzen AI <https://github.com/amd/RyzenAI-SW/tree/main/demo/multi-model-exec>`_ 



- `Hello World using a Jupyer Notebook <https://github.com/amd/RyzenAI-SW/tree/main/tutorial/hello_world>`_
- `End-to-end Object Detection <https://github.com/amd/RyzenAI-SW/tree/main/tutorial/yolov8_e2e>`_
- `Quantization for Ryzen AI <https://github.com/amd/RyzenAI-SW/tree/main/tutorial/RyzenAI_quant_tutorial>`_

