.. include:: /icons.txt

#######################
Application Development
#######################

This page captures requirements and recommendations for developers looking to create, package and distribute applications targeting NPU-enabled AMD processors.


************************************
Application Development Requirements
************************************

ONNX-RT Session
===============

The application should only use the Vitis AI Execution Provider if the following conditions are met:

- The application is running on an AMD processor with a :ref:`NPU type supported by the version of the Vitis AI EP<apu-types>` being used.
- :ref:`NPU drivers compatible with the version of the Vitis AI EP <driver-compatibility>` being used are installed.

|memo| **NOTE**: Sample C++ code implementing the compatibility checks to be performed before using the VitisAI EP is provided here: https://github.com/amd/RyzenAI-SW/tree/main/utilities/npu_check

The application should use XCLBIN file (through ``xclbin`` provider option) correctly according to the APU type (for INT8 models)

The application should use ``vaip_config.json`` which was used to compile BF16 model (for bf16 models). 


Cache Management
================

Cache directories generated by the Vitis AI Execution Provider should not be reused across different versions of the Vitis AI EP or across different version of the NPU drivers.

The application should check the version of the Vitis AI EP and of the NPU drivers. If the application detects a version change, it should delete the cache, or create a new cache directory with a different name.

|

**********************************
Application Packaging Requirements
**********************************

A C++ application built on the Ryzen AI ONNX Runtime requires the following components to be included in its distribution package:

- Runtime DLLs from the Ryzen AI installation area (Installed by the full installer)

  - For INT8, BF16 Models include DLLs from ``C:\Program Files\RyzenAI\<version>\deployment\voe`` 
  - For LLM include DLLs from ``C:\Program Files\RyzenAI\<version>\deployment\npu-llm`` and ``C:\Program Files\RyzenAI\<version>\deployment\hybrid-llm`` 
- NPU Binary files (XCLBIN) for INT8 Models.
- Vitis AI Execution Provider Configuration File: ``vaip_config.json`` for bf16 models
- Pre-compiled models: From the Vitis AI EP cache folder or using Onnx Runtime EP context model 





..
  ------------

  #####################################
  License
  #####################################

 Ryzen AI is licensed under `MIT License <https://github.com/amd/ryzen-ai-documentation/blob/main/License>`_ . Refer to the `LICENSE File <https://github.com/amd/ryzen-ai-documentation/blob/main/License>`_ for the full license text and copyright notice.
